{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |  |\n",
    "| ---: | :--- | :--- |\n",
    "| Курс:| Машинное обучение для текстов | 12 |\n",
    "| Срок обучения на момент сдачи: | 6 месяцев |\n",
    "\n",
    "\n",
    "# Поиск токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта и постановка задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import warnings\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "#from scipy import stats as st\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression #, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier #,DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "#from sklearn.ensemble import RandomForestRegressor #,RandomForestClassifier\n",
    "#from sklearn.dummy import DummyRegressor#, DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import f1_score #, mean_squared_error, make_scorer, mean_absolute_error, r2_score, \n",
    "                                           #accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "#from catboost import CatBoostRegressor #,CatBoostClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier #,LGBMClassifier, LGBMRegressor\n",
    "\n",
    "#from pymystem3 import Mystem\n",
    "\n",
    "import re\n",
    "\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32009</th>\n",
       "      <td>General POV Comments</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102966</th>\n",
       "      <td>Dogmatic \\n\\nThe use of the word dogmatic in r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86879</th>\n",
       "      <td>Editor Interaction Analyzer \\n\\nThanks for you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149769</th>\n",
       "      <td>Bill McNeal is an idiot who thinks he's right,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72932</th>\n",
       "      <td>\"\\n\\nGeorgewilliamherbert, you are intimately ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "32009                                General POV Comments      0\n",
       "102966  Dogmatic \\n\\nThe use of the word dogmatic in r...      0\n",
       "86879   Editor Interaction Analyzer \\n\\nThanks for you...      0\n",
       "149769  Bill McNeal is an idiot who thinks he's right,...      1\n",
       "72932   \"\\n\\nGeorgewilliamherbert, you are intimately ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    '''переводит в нижний регистр, оставляет только латиницу, удаляет stop_words'''\n",
    "    \n",
    "    stop_words = set(nltk_stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "    word_notstop_list = [w for w in word_list if not w in stop_words]\n",
    "    return ' '.join(word_notstop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39405</th>\n",
       "      <td>Stavros Damianides\\nHi. I have recently come u...</td>\n",
       "      <td>0</td>\n",
       "      <td>stavros damianides hi recently come personal a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22826</th>\n",
       "      <td>\"To whom it may concern. hello I am a student ...</td>\n",
       "      <td>0</td>\n",
       "      <td>may concern hello student univeristy computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141380</th>\n",
       "      <td>I guess you should point out French defense mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>guess point french defense minister jean yves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75526</th>\n",
       "      <td>How do i create an new article if there is alr...</td>\n",
       "      <td>0</td>\n",
       "      <td>create new article already one name wanted cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157698</th>\n",
       "      <td>F YOU: YOU IDIOT! YOU ARE PROBABLY JUST JEALOU...</td>\n",
       "      <td>1</td>\n",
       "      <td>f idiot probably jealous cant add make sorry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "39405   Stavros Damianides\\nHi. I have recently come u...      0   \n",
       "22826   \"To whom it may concern. hello I am a student ...      0   \n",
       "141380  I guess you should point out French defense mi...      0   \n",
       "75526   How do i create an new article if there is alr...      0   \n",
       "157698  F YOU: YOU IDIOT! YOU ARE PROBABLY JUST JEALOU...      1   \n",
       "\n",
       "                                               clean_text  \n",
       "39405   stavros damianides hi recently come personal a...  \n",
       "22826   may concern hello student univeristy computer ...  \n",
       "141380  guess point french defense minister jean yves ...  \n",
       "75526   create new article already one name wanted cre...  \n",
       "157698       f idiot probably jealous cant add make sorry  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    \n",
    "    '''Лемматизирует строку WordNetLemmatizer'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "data['wnl_text'] = data['clean_text'].apply(lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация WordNetLemmatizer + pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_lemm_text(text):\n",
    "    \n",
    "    '''Лемматизирует строку WordNetLemmatizer с учетом nltk.pos_tag'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4881\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "data['wnlpostag_text'] = data['clean_text'].apply(postag_lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39488</th>\n",
       "      <th>65092</th>\n",
       "      <th>27021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>\"Please explain the terms \"\"tinfoil hattery\"\" ...</td>\n",
       "      <td>I left some notes on the talk page. I have als...</td>\n",
       "      <td>\"\\n\\n I have  read various pieces by Dr Mehdi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_text</th>\n",
       "      <td>please explain terms tinfoil hattery wackjob v...</td>\n",
       "      <td>left notes talk page also drafting another org...</td>\n",
       "      <td>read various pieces dr mehdi khaz ali listened...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnl_text</th>\n",
       "      <td>please explain term tinfoil hattery wackjob va...</td>\n",
       "      <td>left note talk page also drafting another orga...</td>\n",
       "      <td>read various piece dr mehdi khaz ali listened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnlpostag_text</th>\n",
       "      <td>please explain term tinfoil hattery wackjob va...</td>\n",
       "      <td>left note talk page also draft another organiz...</td>\n",
       "      <td>read various piece dr mehdi khaz ali listen va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            39488  \\\n",
       "text            \"Please explain the terms \"\"tinfoil hattery\"\" ...   \n",
       "toxic                                                           0   \n",
       "clean_text      please explain terms tinfoil hattery wackjob v...   \n",
       "wnl_text        please explain term tinfoil hattery wackjob va...   \n",
       "wnlpostag_text  please explain term tinfoil hattery wackjob va...   \n",
       "\n",
       "                                                            65092  \\\n",
       "text            I left some notes on the talk page. I have als...   \n",
       "toxic                                                           0   \n",
       "clean_text      left notes talk page also drafting another org...   \n",
       "wnl_text        left note talk page also drafting another orga...   \n",
       "wnlpostag_text  left note talk page also draft another organiz...   \n",
       "\n",
       "                                                            27021  \n",
       "text            \"\\n\\n I have  read various pieces by Dr Mehdi ...  \n",
       "toxic                                                           0  \n",
       "clean_text      read various pieces dr mehdi khaz ali listened...  \n",
       "wnl_text        read various piece dr mehdi khaz ali listened ...  \n",
       "wnlpostag_text  read various piece dr mehdi khaz ali listen va...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#промежуточно сохраняю файл с очищенными и лемматизированными комментариями\n",
    "'''\n",
    "data.to_csv('data_lemm2.csv', index=False)\n",
    "data = pd.read_csv('data_lemm2.csv')''';\n",
    "display(data.sample(3).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поковырял документацию. Инструмент серьезный и просто лемматизировать на нем - как \"забивать гвозди микроскопом\". На датасете из 160тыс. комментариев даже исключая ненужные возможности работать будет очень долго. Возможно позже попробую векторизировать с помощью spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import spacy\n",
    "from spacy.lang.en import English''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''pip install -U spacy''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def spacy_lemm_text(text):\n",
    "    lemmatizer = spacy.load('en_core_web_sm', disable=[\"parser\", \"ner\"])\n",
    "    doc = lemmatizer(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data2 = data[0:100].copy()''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply(spacy_lemm_text) для 1000 строк заняла 880 секунд (весь df будет лемматизировать очень долго)\n",
    "'''\n",
    "beg_time = datetime.datetime.now()\n",
    "data2['spacy_text'] = data2['clean_text'].apply(spacy_lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''display(data2.sample(3).T)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['wnl_text'].astype('U').values\n",
    "corpus_2 = data['wnlpostag_text'].astype('U').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_2 = TfidfVectorizer()\n",
    "tf_idf_2 = count_tf_idf_2.fit_transform(corpus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    tf_idf, \n",
    "    data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_2, features_test_2, target_train_2, target_test_2 = train_test_split(\n",
    "    tf_idf_2, \n",
    "    data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.758 модель: LogisticRegression данные: wnl_text время работы модели: 25\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_1 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "model_1.mod = 'model_1'\n",
    "model_1.name = 'LogisticRegression'\n",
    "model_1.data = 'wnl_text'\n",
    "model_1.f1 = cross_val_score(model_1, features_train, target_train, cv=kfold, scoring='f1')\n",
    "model_1.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_1.f1.mean()), \n",
    "      'модель:', model_1.name, \n",
    "      'данные:', model_1.data, \n",
    "      'время работы модели:', model_1.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.757 модель: LogisticRegression данные: wnlpostag_text время работы модели: 25\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_2 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "model_2.mod = 'model_2'\n",
    "model_2.name = 'LogisticRegression'\n",
    "model_2.data = 'wnlpostag_text'\n",
    "model_2.f1 = cross_val_score(model_2, features_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_2.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_2.f1.mean()), \n",
    "      'модель:', model_2.name, \n",
    "      'данные:', model_2.data, \n",
    "      'время работы модели:', model_2.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.659 модель: DecisionTreeClassifier данные: wnl_text время работы модели: 1688\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_3 = DecisionTreeClassifier(class_weight='balanced', random_state=123)\n",
    "\n",
    "model_3.mod = 'model_3'\n",
    "model_3.name = 'DecisionTreeClassifier'\n",
    "model_3.data = 'wnl_text'\n",
    "model_3.f1 = cross_val_score(model_3, features_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_3.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_3.f1.mean()), \n",
    "      'модель:', model_3.name, \n",
    "      'данные:', model_3.data, \n",
    "      'время работы модели:', model_3.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.666 модель: DecisionTreeClassifier данные: wnlpostag_text время работы модели: 1433\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_4 = DecisionTreeClassifier(class_weight='balanced', random_state=123)\n",
    "\n",
    "model_4.mod = 'model_4'\n",
    "model_4.name = 'DecisionTreeClassifier'\n",
    "model_4.data = 'wnlpostag_text'\n",
    "model_4.f1 = cross_val_score(model_4, features_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_4.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_4.f1.mean()), \n",
    "      'модель:', model_4.name, \n",
    "      'данные:', model_4.data, \n",
    "      'время работы модели:', model_4.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.729 модель: LGBMClassifier 50 данные: wnl_text время работы модели: 336\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_5 = LGBMClassifier(n_estimators=50, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_5.mod = 'model_5'\n",
    "model_5.name = 'LGBMClassifier 50'\n",
    "model_5.data = 'wnl_text'\n",
    "model_5.f1 = cross_val_score(model_5, features_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_5.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_5.f1.mean()), \n",
    "      'модель:', model_5.name, \n",
    "      'данные:', model_5.data, \n",
    "      'время работы модели:', model_5.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.729 модель: LGBMClassifier 50 данные: wnlpostag_text время работы модели: 279\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_6 = LGBMClassifier(n_estimators=50, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_6.mod = 'model_6'\n",
    "model_6.name = 'LGBMClassifier 50'\n",
    "model_6.data = 'wnlpostag_text'\n",
    "model_6.f1 = cross_val_score(model_6, features_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_6.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_6.f1.mean()), \n",
    "      'модель:', model_6.name, \n",
    "      'данные:', model_6.data, \n",
    "      'время работы модели:', model_6.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.769 модель: LGBMClassifier 500 данные: wnl_text время работы модели: 1451\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_7 = LGBMClassifier(n_estimators=500, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_7.mod = 'model_7'\n",
    "model_7.name = 'LGBMClassifier 500'\n",
    "model_7.data = 'wnl_text'\n",
    "model_7.f1 = cross_val_score(model_7, features_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_7.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_7.f1.mean()), \n",
    "      'модель:', model_7.name, \n",
    "      'данные:', model_7.data, \n",
    "      'время работы модели:', model_7.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.729 модель: LGBMClassifier 500 данные: wnlpostag_text время работы модели: 211\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_8 = LGBMClassifier(n_estimators=500, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_8.mod = 'model_8'\n",
    "model_8.name = 'LGBMClassifier 500'\n",
    "model_8.data = 'wnlpostag_text'\n",
    "model_8.f1 = cross_val_score(model_5, features_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_8.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_8.f1.mean()), \n",
    "      'модель:', model_8.name, \n",
    "      'данные:', model_8.data, \n",
    "      'время работы модели:', model_8.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={}\n",
    "for i in model_list:\n",
    "    b={}    \n",
    "    b['model']=i.name\n",
    "    b['data']=i.data\n",
    "    b['f1_score']=i.f1.mean()\n",
    "    b['cross_val_time']=i.time\n",
    "    a[i.mod] = b\n",
    "\n",
    "final_table = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cross_val_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.758474</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.757118</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.658575</td>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.665997</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.729446</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.729446</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model            data  f1_score cross_val_time\n",
       "model_1      LogisticRegression        wnl_text  0.758474             25\n",
       "model_2      LogisticRegression  wnlpostag_text  0.757118             25\n",
       "model_3  DecisionTreeClassifier        wnl_text  0.658575           1688\n",
       "model_4  DecisionTreeClassifier  wnlpostag_text  0.665997           1433\n",
       "model_5       LGBMClassifier 50        wnl_text  0.728778            336\n",
       "model_6       LGBMClassifier 50  wnlpostag_text  0.729446            279\n",
       "model_7      LGBMClassifier 500        wnl_text  0.769447           1451\n",
       "model_8      LGBMClassifier 500  wnlpostag_text  0.729446            211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7521367521367522\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(features_train, target_train)\n",
    "model_1.predicted = model_1.predict(features_test)\n",
    "model_1.test_f1 = f1_score(target_test, model_1.predicted)\n",
    "print(model_1.test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7665763581919293\n"
     ]
    }
   ],
   "source": [
    "model_7.fit(features_train, target_train)\n",
    "model_7.predicted = model_7.predict(features_test)\n",
    "model_7.test_f1 = f1_score(target_test, model_7.predicted)\n",
    "print(model_7.test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие результаты показала модель LGBMClassifier с n_estimators=500 и логистическая регрессия на менее обработанных данных (лемматизация без учета части речи). При этом логистическая регрессия значительно быстрее. Увеличение метрик возможно за счет подбора более результативных вариантов предобработки, перебора гиперпараметров и использования более серьезных специализированных инструментов, но такие мероприятия более ресурсоёмки (требуют использования более произодительных вычислительных мощностей или увеличения времени обработки задачи).\n",
    "\n",
    "Установленное значение метрики f1 (0.75) было достигнуто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
